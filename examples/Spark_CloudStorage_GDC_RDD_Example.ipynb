{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.partitions.map(_.asInstanceOf[GdcRDDPartition[CloudStorageFile]].gdcFile)\n",
    "rdd.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%md\n",
    "\n",
    "# Example for reading data from a Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dep\n",
    "\n",
    "z.load(\"PATH_TO_PROJECT/gdc-spark_2x/target/scala-2.11/gdc-spark_2x-assembly-0.2.0-SNAPSHOT.jar\")\n",
    "z.load(\"PATH_TO_PROJECT/gdc-google/target/scala-2.11/gdc-google-assembly-0.2.0-SNAPSHOT.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.streaming.gdc._\n",
    "import es.alvsanand.gdc.google.cloud_storage._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val parameters = CloudStorageParameters(\"PATH_TO_CREDENTIALS/credentials.zip\", \"BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rdd = sc.createDownloadRDD(CloudStorageGdcDownloaderFactory, parameters)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}